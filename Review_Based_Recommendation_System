{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems Based On Amazon Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teammates: Nivetitha Ramachandar, Zhirou Zhang, Supriya Tiwari, Jiamin Zhu, Shruti Deshpande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the outline of what we're going to do in this notebook.\n",
    "- Problem Statement,Objective\n",
    "- Overview and Benefits of review based engine\n",
    "- Dataset Overview\n",
    "- Data cleaning steps \n",
    "- Sentiment Analysis \n",
    "- Word2vec model \n",
    "- Recommendation Results\n",
    "- Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the bacis information of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reviewerID: ID of the reviewer\n",
    "- asin: ID of the product\n",
    "- reviewerName: name of the reviewer\n",
    "- helpful: helpfulness rating of the review, e.g. 2/3\n",
    "- reviewText:  text of the review\n",
    "- overall: rating score from 0 to 5\n",
    "- summary: summary of the review\n",
    "- unixReviewTime: time of the review (unix time)\n",
    "- reviewTime: time of the review (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"reviews_Clothing_Shoes_and_Jewelry_5.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>02 12, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Cute!!</td>\n",
       "      <td>1358553600</td>\n",
       "      <td>01 19, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Carola</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>5</td>\n",
       "      <td>I have buy more than one</td>\n",
       "      <td>1357257600</td>\n",
       "      <td>01 4, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "      <td>1398556800</td>\n",
       "      <td>04 27, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>CJ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>5</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>03 15, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                 reviewerName helpful  \\\n",
       "0  A1KLRMWW2FWPL4  0000031887  Amazon Customer \"cameramom\"  [0, 0]   \n",
       "1  A2G5TCU2WDFZ65  0000031887              Amazon Customer  [0, 0]   \n",
       "2  A1RLQXYNCMWRWN  0000031887                       Carola  [0, 0]   \n",
       "3   A8U3FAMSJVHS5  0000031887                      Caromcg  [0, 0]   \n",
       "4  A3GEOILWLK86XM  0000031887                           CJ  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is a great tutu and at a really great pri...        5   \n",
       "1  I bought this for my 4 yr old daughter for dan...        5   \n",
       "2  What can I say... my daughters have it in oran...        5   \n",
       "3  We bought several tutus at once, and they are ...        5   \n",
       "4  Thank you Halo Heaven great product for Little...        5   \n",
       "\n",
       "                         summary  unixReviewTime   reviewTime  \n",
       "0  Great tutu-  not cheaply made      1297468800  02 12, 2011  \n",
       "1                    Very Cute!!      1358553600  01 19, 2013  \n",
       "2       I have buy more than one      1357257600   01 4, 2013  \n",
       "3               Adorable, Sturdy      1398556800  04 27, 2014  \n",
       "4        Grammy's Angels Love it      1394841600  03 15, 2014  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we'll extract only reviews text from the data and store it in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 µs, sys: 46 µs, total: 95 µs\n",
      "Wall time: 103 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_REVIEWS_TEXT = True\n",
    "\n",
    "from os import path\n",
    "reviews_text_filepath = 'medium/reviews_text.txt'\n",
    "if not USE_PREMADE_REVIEWS_TEXT:\n",
    "    with open(reviews_text_filepath, 'w') as f:\n",
    "        for review in data.reviewText.values:\n",
    "            # if the row lacks a review, skip it.\n",
    "            if pd.isnull(review):\n",
    "                continue\n",
    "            f.write(review + '\\n')\n",
    "else:\n",
    "    assert path.exists(reviews_text_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple function which helps us read each line from the reviews text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reviews(filepath):\n",
    "    \"\"\"\n",
    "    helper function to read in the file and yield each line at a time.\n",
    "    \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        for review in f:\n",
    "            yield review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def retrieve_review(sample_num):\n",
    "    \"\"\"\n",
    "    get a specific review from reviews text file and return it.\n",
    "    \"\"\"\n",
    "    return next(islice(read_reviews(reviews_text_filepath), sample_num, sample_num+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a sample and see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'got for my niece and she had a blast with it. the only bad this is that the little parts all get lost and now she does not have half of them.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review = retrieve_review(200)\n",
    "sample_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PROCESSING WITH SPACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use spaCy to normalize reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 344 ms, total: 1.95 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import spacy\n",
    "# load english vocabulary and language models. This takes some time.\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(line):\n",
    "    \"\"\"\n",
    "    remove punctuation and whitespace.\n",
    "    \"\"\"\n",
    "    return [token.lemma_ for token in line \n",
    "                      if not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well spaCy did. Here's a normalized version of the sample review above. You can see that many words have been lowered & stemmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get for -PRON- niece and -PRON- have a blast with -PRON- the only bad this be that the little part all get lose and now -PRON- do not have half of -PRON-'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_normalized = lemmatize(nlp(sample_review))\n",
    "' '.join(sample_review_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform normalizatioin for all the reviews we have. This takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 µs, sys: 87 µs, total: 140 µs\n",
      "Wall time: 85.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_SENTENCES_NORMALIZED = True\n",
    "\n",
    "sentences_normalized_filepath = 'medium/sentences_normalized.txt'\n",
    "\n",
    "\n",
    "if not USE_PREMADE_SENTENCES_NORMALIZED:\n",
    "    with open(sentences_normalized_filepath, 'w') as f:\n",
    "        for review_parsed in nlp.pipe(read_reviews(reviews_text_filepath)):\n",
    "            for sentence_parsed in review_parsed.sents:\n",
    "                lemmas = lemmatize(sentence_parsed)\n",
    "                f.write(' '.join(lemmas) + '\\n')\n",
    "else:\n",
    "    assert path.exists(sentences_normalized_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are words which are often used together, and which get a special meaning when they're used together. We call them 'phrases'. We're now going to find bigram/trigram phrases from the reviews.\n",
    "\n",
    "To do so, we turn to the famous NLP library in Python, gensim. Particularly, the Phrases class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the normalized texts from the previous section, and build a bigram model upon them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 220 ms, total: 1.86 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_BIGRAM_MODEL = True\n",
    "\n",
    "bigram_model_filepath = 'medium/bigram_model.dms'\n",
    "\n",
    "# gensim's LineSentence provies a convenient way to iterate over lines in a text file.\n",
    "# it outputs one line at a time, so you can save memory space. it works well with other gensim components.\n",
    "from gensim.models.word2vec import LineSentence\n",
    "# we take normalized sentences as unigram sentences, which means we didn't apply any phrase modeling yet.\n",
    "unigram_sentences = LineSentence(sentences_normalized_filepath)\n",
    "\n",
    "if not USE_PREMADE_BIGRAM_MODEL:    \n",
    "    \n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "    \n",
    "else:\n",
    "    bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get for -PRON- niece and -PRON- have a blast with -PRON- the only bad this be that the little part all get lose and now -PRON- do not have half of -PRON-'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_bigram = bigram_model[sample_review_normalized]\n",
    "' '.join(sample_review_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process all the normalized texts in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55 µs, sys: 215 µs, total: 270 µs\n",
      "Wall time: 235 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_BIGRAM_SENTENCES = True\n",
    "\n",
    "bigram_sentences_filepath = 'medium/bigram_sentences.txt'\n",
    "\n",
    "if not USE_PREMADE_BIGRAM_SENTENCES:\n",
    "    \n",
    "    with open(bigram_sentences_filepath, 'w') as f:\n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            bigram_sentence = bigram_model[unigram_sentence]\n",
    "            f.write(' '.join(bigram_sentence) + '\\n')\n",
    "else:\n",
    "    assert path.exists(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one step further. We're going to build a trigram phrase model on bigram model. It means, we can combine together two bigram phrases, or one unigram and one bigram phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 s, sys: 1.07 s, total: 3.03 s\n",
      "Wall time: 3.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_TRIGRAM_MODEL = True\n",
    "\n",
    "trigram_model_filepath = 'medium/trigram_model.dms'\n",
    "\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Phrases\n",
    "\n",
    "if not USE_PREMADE_TRIGRAM_MODEL:\n",
    "    \n",
    "    bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "\n",
    "else:\n",
    "    trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/zoey/opt/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/zoey/opt/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 969 ms, sys: 599 ms, total: 1.57 s\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import spacy\n",
    "# load english vocabulary and language models. This takes some time.\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (2.3.4)\n",
      "Requirement already satisfied: setuptools in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (41.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.17.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (4.51.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (7.2.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: setuptools in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (41.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.9.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (41.4.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/zoey/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/zoey/opt/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/zoey/opt/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 222 µs, sys: 1.39 ms, total: 1.61 ms\n",
      "Wall time: 2.74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_REVIEWS_FOR_LDA = True\n",
    "\n",
    "reviews_for_lda_filepath = 'medium/reviews_for_lda.txt'\n",
    "\n",
    "if not USE_PREMADE_REVIEWS_FOR_LDA:\n",
    "    \n",
    "    with open(reviews_for_lda_filepath, 'w') as f:\n",
    "        \n",
    "        for review_parsed in nlp.pipe(read_reviews(reviews_text_filepath)):\n",
    "            \n",
    "            unigram_review = lemmatize(review_parsed)\n",
    "            bigram_review = bigram_model[unigram_review]\n",
    "            trigram_review = trigram_model[bigram_review]\n",
    "            # remove stop words\n",
    "            trimmed_review = [lemma for lemma in trigram_review \n",
    "                              if lemma not in spacy.lang.en.STOP_WORDS and lemma != '-PRON-']\n",
    "            f.write(' '.join(trimmed_review) + '\\n')\n",
    "else:\n",
    "    assert path.exists(reviews_for_lda_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 682 µs, sys: 1.07 ms, total: 1.75 ms\n",
      "Wall time: 1.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_SENTENCES_FOR_WORD2VEC = True\n",
    "\n",
    "sentences_for_word2vec_filepath = 'medium/sentences_for_word2vec.txt'\n",
    "\n",
    "if not USE_PREMADE_SENTENCES_FOR_WORD2VEC:\n",
    "    \n",
    "    with open(sentences_for_word2vec_filepath, 'w') as f:\n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            trigram_sentence = trigram_model[bigram_sentence]\n",
    "            # remove stop words\n",
    "            trimmed_sentence = [lemma for lemma in trigram_sentence \n",
    "                                if lemma not in spacy.lang.en.STOP_WORDS and lemma != '-PRON-']\n",
    "            f.write(' '.join(trimmed_sentence) + '\\n')\n",
    "else:\n",
    "    assert path.exists(sentences_for_word2vec_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is to automatically find topics from a bunch of documents - reviews, in this case. We'll now perform LDA, the most basic topic modeling method, on our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to compile our dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 ms, sys: 5.28 ms, total: 18.9 ms\n",
      "Wall time: 23.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_DICTIONARY = True\n",
    "\n",
    "dictionary_filepath = 'medium/dictionary.dict'\n",
    "\n",
    "if not USE_PREMADE_DICTIONARY:\n",
    "    \n",
    "    reviews_for_lda = LineSentence(reviews_for_lda_filepath)\n",
    "    dictionary = Dictionary(reviews_for_lda)\n",
    "    dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    dictionary.save(dictionary_filepath)\n",
    "else:\n",
    "    dictionary = Dictionary.load(dictionary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we build a corpus which we'll use when performing LDA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.7 ms, sys: 12.6 ms, total: 64.3 ms\n",
      "Wall time: 91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_CORPUS = True\n",
    "\n",
    "corpus_filepath = 'medium/corpus.mm'\n",
    "\n",
    "if not USE_PREMADE_CORPUS:\n",
    "    \n",
    "    def make_bow_corpus(filepath):\n",
    "        \"\"\"\n",
    "        generator function to read in reviews from the file\n",
    "        and output a bag-of-words represention of the text\n",
    "        \"\"\"\n",
    "        for review in LineSentence(filepath):\n",
    "            yield dictionary.doc2bow(review)\n",
    "            \n",
    "    MmCorpus.serialize(corpus_filepath, make_bow_corpus(reviews_for_lda_filepath))\n",
    "    \n",
    "review_corpus = MmCorpus(corpus_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can turn to gensim's LdaMulticore class for parallelized LDA, which is claimed to be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.8 ms, sys: 23.2 ms, total: 59 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_LDA = True\n",
    "\n",
    "lda_filepath = 'medium/lda.dms'\n",
    "\n",
    "if not USE_PREMADE_LDA:\n",
    "    \n",
    "    # number of workers should be set to your number of physical cores minus one\n",
    "    lda = LdaMulticore(review_corpus,\n",
    "                           num_topics=20,\n",
    "                           id2word=dictionary,\n",
    "                           workers=2)\n",
    "    lda.save(lda_filepath)\n",
    "else:\n",
    "    lda = LdaMulticore.load(lda_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect a specific topic from the model by it's index. There's no names for topics, though, because LDA is an unsupervised learning algorithm. Instead, you can see the words associated to the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wear', 0.070764236),\n",
       " ('cute', 0.060950752),\n",
       " ('little', 0.03840767),\n",
       " ('buy', 0.025836447),\n",
       " ('love', 0.020183604),\n",
       " ('like', 0.018883679),\n",
       " ('daughter', 0.0186673),\n",
       " ('big', 0.01735082),\n",
       " ('think', 0.016467638),\n",
       " ('fit', 0.014945062)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#df_lda.distplot(df['petal_length'],kde = False)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on previous findings, we conduct sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (2.3.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (47.3.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/jiaminzhu/.local/lib/python3.7/site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (4.51.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (7.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3 is available.\n",
      "You should consider upgrading via the '/Users/jiaminzhu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: setuptools in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (47.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/jiaminzhu/.local/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.23)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/Users/jiaminzhu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/jiaminzhu/.local/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: setuptools in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (47.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/Users/jiaminzhu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# spaCy stuff\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en\n",
    "\n",
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>02 12, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Cute!!</td>\n",
       "      <td>1358553600</td>\n",
       "      <td>01 19, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Carola</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>5</td>\n",
       "      <td>I have buy more than one</td>\n",
       "      <td>1357257600</td>\n",
       "      <td>01 4, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "      <td>1398556800</td>\n",
       "      <td>04 27, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>CJ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>5</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>03 15, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                 reviewerName helpful  \\\n",
       "0  A1KLRMWW2FWPL4  0000031887  Amazon Customer \"cameramom\"  [0, 0]   \n",
       "1  A2G5TCU2WDFZ65  0000031887              Amazon Customer  [0, 0]   \n",
       "2  A1RLQXYNCMWRWN  0000031887                       Carola  [0, 0]   \n",
       "3   A8U3FAMSJVHS5  0000031887                      Caromcg  [0, 0]   \n",
       "4  A3GEOILWLK86XM  0000031887                           CJ  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is a great tutu and at a really great pri...        5   \n",
       "1  I bought this for my 4 yr old daughter for dan...        5   \n",
       "2  What can I say... my daughters have it in oran...        5   \n",
       "3  We bought several tutus at once, and they are ...        5   \n",
       "4  Thank you Halo Heaven great product for Little...        5   \n",
       "\n",
       "                         summary  unixReviewTime   reviewTime  \n",
       "0  Great tutu-  not cheaply made      1297468800  02 12, 2011  \n",
       "1                    Very Cute!!      1358553600  01 19, 2013  \n",
       "2       I have buy more than one      1357257600   01 4, 2013  \n",
       "3               Adorable, Sturdy      1398556800  04 27, 2014  \n",
       "4        Grammy's Angels Love it      1394841600  03 15, 2014  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = data\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customer overall rating is from 0 to 5. \n",
    "In order to simplify the problem we will split those into two categories: \n",
    "bad reviews: overall ratings < 3 \n",
    "good reviews: overall ratings >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  is_bad_review\n",
       "0  This is a great tutu and at a really great pri...              0\n",
       "1  I bought this for my 4 yr old daughter for dan...              0\n",
       "2  What can I say... my daughters have it in oran...              0\n",
       "3  We bought several tutus at once, and they are ...              0\n",
       "4  Thank you Halo Heaven great product for Little...              0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the label\n",
    "reviews_df[\"is_bad_review\"] = reviews_df[\"overall\"].apply(lambda x: 1 if x < 3 else 0)\n",
    "# select only relevant columns\n",
    "reviews_df = reviews_df[[\"reviewText\", \"is_bad_review\"]]\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews data is sampled in order to speed up computations.\n",
    "reviews_df = reviews_df.sample(frac = 0.1, replace = False, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the customer doesn't leave any negative/positive review, this will apprear as \"No negative\" or \"No positive\" in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'No Negative' or 'No Positive' from text\n",
    "reviews_df[\"reviewText\"] = reviews_df[\"reviewText\"].apply(lambda x: x.replace(\"No Negative\", \"\").replace(\"No Positive\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the wordnet object value corresponding to the POS tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "# clean text data\n",
    "reviews_df[\"review_clean\"] = reviews_df[\"reviewText\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the process of cleanning reviewText data, we did following things:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lower the text\n",
    "- tokenize the text (split the text into words) and remove the punctuation\n",
    "- remove useless words that contain numbers\n",
    "- remove useless stop words like 'the', 'a' ,'this' etc.\n",
    "- Part-Of-Speech (POS) tagging: assign a tag to every word to define if it corresponds to a noun, a verb etc. using - the WordNet lexical database\n",
    "- lemmatize the text: transform every word into their root form (e.g. rooms -> room, slept -> sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>207149</td>\n",
       "      <td>I put this bra in my Amazon cart months ago wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>put bra amazon cart month ago look cheap versi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81474</td>\n",
       "      <td>I was a Brooks girl for several years (well a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>brook girl several year well couple decade act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158023</td>\n",
       "      <td>I have had these for about 4 months and I'm no...</td>\n",
       "      <td>0</td>\n",
       "      <td>month i'm exactly sure size gain little weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223085</td>\n",
       "      <td>Cutest boots ever, they go great with leggings...</td>\n",
       "      <td>0</td>\n",
       "      <td>cutest boot ever go great legging cute sweater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119212</td>\n",
       "      <td>Sweatshirt material. Wind will cut right throu...</td>\n",
       "      <td>1</td>\n",
       "      <td>sweatshirt material wind cut right jacket.i ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  is_bad_review  \\\n",
       "207149  I put this bra in my Amazon cart months ago wh...              0   \n",
       "81474   I was a Brooks girl for several years (well a ...              0   \n",
       "158023  I have had these for about 4 months and I'm no...              0   \n",
       "223085  Cutest boots ever, they go great with leggings...              0   \n",
       "119212  Sweatshirt material. Wind will cut right throu...              1   \n",
       "\n",
       "                                             review_clean  \n",
       "207149  put bra amazon cart month ago look cheap versi...  \n",
       "81474   brook girl several year well couple decade act...  \n",
       "158023  month i'm exactly sure size gain little weight...  \n",
       "223085  cutest boot ever go great legging cute sweater...  \n",
       "119212  sweatshirt material wind cut right jacket.i ge...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jiaminzhu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Vader to conduct sentiment analysis. Vader uses a lexicon of words to find which ones are positives or negatives. It also takes into accout the context of the sentences to determine the sentiment scores.For each text, Vader retuns 4 values:\n",
    "\n",
    "- a neutrality score\n",
    "- a positivity score\n",
    "- a negativity score\n",
    "- an overall score that summarizes the previous scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will integrate those 4 values as features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment anaylsis columns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "reviews_df[\"sentiments\"] = reviews_df[\"reviewText\"].apply(lambda x: sid.polarity_scores(x))\n",
    "reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add some simple metrics for every text:\n",
    "- number of characters in the text\n",
    "- number of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of characters column\n",
    "reviews_df[\"nb_chars\"] = reviews_df[\"reviewText\"].apply(lambda x: len(x))\n",
    "\n",
    "# add number of words column\n",
    "reviews_df[\"nb_words\"] = reviews_df[\"reviewText\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step consist in extracting vector representations for every review. The module Gensim creates a numerical vector representation of every word in the corpus by using the contexts in which they appear (Word2Vec)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each text can also be transformed into numerical vectors using the word vectors (Doc2Vec). Same texts will also have similar representations and that is why we can use those vectors as training features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to train a Doc2Vec model by feeding in our text data. By applying this model on our reviews, we can get those representation vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create doc2vec vector columns\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews_df[\"review_clean\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# train a Doc2Vec model with our text data\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document into a vector data\n",
    "doc2vec_df = reviews_df[\"review_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
    "reviews_df = pd.concat([reviews_df, doc2vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the TF-IDF (Term Frequency - Inverse Document Frequency) values for every word and every document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tf-idfs columns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 10)\n",
    "tfidf_result = tfidf.fit_transform(reviews_df[\"review_clean\"]).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "tfidf_df.index = reviews_df.index\n",
    "reviews_df = pd.concat([reviews_df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviewnew_df = reviews_df[reviews_df.columns[0:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>207149</td>\n",
       "      <td>I put this bra in my Amazon cart months ago wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>put bra amazon cart month ago look cheap versi...</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81474</td>\n",
       "      <td>I was a Brooks girl for several years (well a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>brook girl several year well couple decade act...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158023</td>\n",
       "      <td>I have had these for about 4 months and I'm no...</td>\n",
       "      <td>0</td>\n",
       "      <td>month i'm exactly sure size gain little weight...</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223085</td>\n",
       "      <td>Cutest boots ever, they go great with leggings...</td>\n",
       "      <td>0</td>\n",
       "      <td>cutest boot ever go great legging cute sweater...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119212</td>\n",
       "      <td>Sweatshirt material. Wind will cut right throu...</td>\n",
       "      <td>1</td>\n",
       "      <td>sweatshirt material wind cut right jacket.i ge...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  is_bad_review  \\\n",
       "207149  I put this bra in my Amazon cart months ago wh...              0   \n",
       "81474   I was a Brooks girl for several years (well a ...              0   \n",
       "158023  I have had these for about 4 months and I'm no...              0   \n",
       "223085  Cutest boots ever, they go great with leggings...              0   \n",
       "119212  Sweatshirt material. Wind will cut right throu...              1   \n",
       "\n",
       "                                             review_clean    neg    neu    pos  \n",
       "207149  put bra amazon cart month ago look cheap versi...  0.128  0.665  0.207  \n",
       "81474   brook girl several year well couple decade act...  0.000  0.708  0.292  \n",
       "158023  month i'm exactly sure size gain little weight...  0.018  0.886  0.096  \n",
       "223085  cutest boot ever go great legging cute sweater...  0.000  0.599  0.401  \n",
       "119212  sweatshirt material wind cut right jacket.i ge...  0.079  0.829  0.093  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewnew_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of comparing raw review and clean review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I put this bra in my Amazon cart months ago while looking for a cheaper version of my favorite brand (Moving Comfort: Fiona). After deciding to stick with what works, I essentially forgot about this item until months later when I accidentally purchased it thinking I had saved a Moving Comfort. When the bra showed up I was so angry that I had made such a stupid mistake, but decided to keep what I thought was a waste of money. Boy was I wrong! I love this bra! It fits great and keeps the ladies in place (which is something hard for a large busted lady to find). It turned out to be a nice surprise and it's my number 1 bra in the rotation.\""
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewnew_df['reviewText'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put bra amazon cart month ago look cheap version favorite brand move comfort fiona decide stick work essentially forget item month later accidentally purchase thinking save move comfort bra show angry make stupid mistake decide keep thought waste money boy wrong love bra fit great keep lady place something hard large bust lady find turn nice surprise number bra rotation'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewnew_df['review_clean'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a better understanding of our data, we are going to exlpore more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.902756\n",
       "1    0.097244\n",
       "Name: is_bad_review, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show is_bad_review distribution\n",
    "reviews_df[\"is_bad_review\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this result, we can imply that our dataset is highly imbalanced because less than 10% of our reviews are consideres as negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>196033</td>\n",
       "      <td>I love it, it's super cute.</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268764</td>\n",
       "      <td>Highly recommended!  Great top...very comforta...</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147705</td>\n",
       "      <td>nice color and top comfort fit!</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277390</td>\n",
       "      <td>Great fit. True to size.</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111923</td>\n",
       "      <td>beautiful fit a sturdy shoe, pleased</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262563</td>\n",
       "      <td>I love, love this dress.</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270404</td>\n",
       "      <td>Was a gift and well liked.</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123164</td>\n",
       "      <td>fit well and look good</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11512</td>\n",
       "      <td>Fits nicely and gives great support, love it!</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246714</td>\n",
       "      <td>beautify  wonderful thank you Hope you have a ...</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText    pos\n",
       "196033                        I love it, it's super cute.  0.847\n",
       "268764  Highly recommended!  Great top...very comforta...  0.838\n",
       "147705                    nice color and top comfort fit!  0.832\n",
       "277390                           Great fit. True to size.  0.825\n",
       "111923               beautiful fit a sturdy shoe, pleased  0.823\n",
       "262563                           I love, love this dress.  0.808\n",
       "270404                         Was a gift and well liked.  0.796\n",
       "123164                             fit well and look good  0.789\n",
       "11512       Fits nicely and gives great support, love it!  0.780\n",
       "246714  beautify  wonderful thank you Hope you have a ...  0.767"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest positive sentiment reviews (with more than 5 words)\n",
    "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"pos\", ascending = False)[[\"reviewText\", \"pos\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result, we found that most positive reviews are related to good feedbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>198241</td>\n",
       "      <td>its very bad low quality</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130581</td>\n",
       "      <td>Too hard and not comfortable</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29584</td>\n",
       "      <td>doesn't fit, is to small. I hate it, don't do ...</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160834</td>\n",
       "      <td>Not a good fit , should have sizes</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55329</td>\n",
       "      <td>not a good walking shoe.</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245137</td>\n",
       "      <td>its very slimming and all but the under clasp ...</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183520</td>\n",
       "      <td>Just needs to be broken in.</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253054</td>\n",
       "      <td>The fabric  not  so good.  It is indeed not a ...</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162035</td>\n",
       "      <td>This is exactly as advertised. You can't help ...</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179846</td>\n",
       "      <td>Horrible quality. Sharp edges stones missing a...</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText    neg\n",
       "198241                           its very bad low quality  0.673\n",
       "130581                       Too hard and not comfortable  0.578\n",
       "29584   doesn't fit, is to small. I hate it, don't do ...  0.534\n",
       "160834                 Not a good fit , should have sizes  0.530\n",
       "55329                            not a good walking shoe.  0.445\n",
       "245137  its very slimming and all but the under clasp ...  0.385\n",
       "183520                        Just needs to be broken in.  0.383\n",
       "253054  The fabric  not  so good.  It is indeed not a ...  0.378\n",
       "162035  This is exactly as advertised. You can't help ...  0.372\n",
       "179846  Horrible quality. Sharp edges stones missing a...  0.359"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest negative sentiment reviews (with more than 5 words)\n",
    "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"neg\", ascending = False)[[\"reviewText\", \"neg\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result, all negative reviews correspond to bad feedbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sentiment distribution for positive and negative reviews\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "for x in [0, 1]:\n",
    "    subset = reviews_df[reviews_df['is_bad_review'] == x]\n",
    "    \n",
    "    # Draw the density plot\n",
    "    if x == 0:\n",
    "        label = \"Good reviews\"\n",
    "    else:\n",
    "        label = \"Bad reviews\"\n",
    "    sns.distplot(subset['compound'], hist = False, label = label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows the distribution of the reviews sentiments among goods reviews and bad ones. We can see that good reviews are for most of them considered as very positive by Vader. On the contrary, bad reviews tend to have lower compound sentiment scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vector modeling with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Word vector modeling (word embedding, put another way) is a method to transform words to vectors, which enables arithmetic with them. Word2Vec has been proposed by Google in 2013, and you can find python implementation of the model in ... gensim (of course!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 359 ms, sys: 234 ms, total: 593 ms\n",
      "Wall time: 647 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "USE_PREMADE_WORD2VEC = True\n",
    "\n",
    "word2vec_filepath = 'medium/word2vec_model.dms'\n",
    "\n",
    "if not USE_PREMADE_WORD2VEC:\n",
    "    \n",
    "    sentences_for_word2vec = LineSentence(sentences_for_word2vec_filepath)\n",
    "    \n",
    "    # initiate the model with 100 dimensions of vectors, 5 words to look before and after each focus word, etc.\n",
    "    # and perform the first epoch of training\n",
    "    model = Word2Vec(sentences_for_word2vec, size=100, window=5, min_count=5, sg=1)\n",
    "    \n",
    "    # perform another 10 epochs of training\n",
    "    for _ in range(9):\n",
    "        model.train(sentences_for_word2vec,epochs=model.iter, total_examples=model.corpus_count)\n",
    "\n",
    "    model.save(word2vec_filepath)\n",
    "else:\n",
    "    model = Word2Vec.load(word2vec_filepath)\n",
    "model.init_sims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 training epochs so far.\n"
     ]
    }
   ],
   "source": [
    "print('{} training epochs so far.'.format(model.train_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transformed each word in our reviews to 100 dimentional vectors. Wonder how they look? here's word vectors in pandas dataframe form.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wear</td>\n",
       "      <td>-0.006471</td>\n",
       "      <td>0.108129</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>-0.138854</td>\n",
       "      <td>0.103454</td>\n",
       "      <td>-0.015824</td>\n",
       "      <td>0.060735</td>\n",
       "      <td>-0.190063</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098226</td>\n",
       "      <td>-0.191005</td>\n",
       "      <td>-0.126301</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>-0.174255</td>\n",
       "      <td>0.028864</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.048451</td>\n",
       "      <td>-0.018639</td>\n",
       "      <td>0.011287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fit</td>\n",
       "      <td>-0.161161</td>\n",
       "      <td>0.110439</td>\n",
       "      <td>-0.038229</td>\n",
       "      <td>-0.026666</td>\n",
       "      <td>-0.144252</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.190725</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>-0.120438</td>\n",
       "      <td>0.081916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>-0.108018</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>-0.109473</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>0.019416</td>\n",
       "      <td>0.073419</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>-0.013740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>0.072590</td>\n",
       "      <td>0.069709</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>-0.031151</td>\n",
       "      <td>-0.212090</td>\n",
       "      <td>0.035488</td>\n",
       "      <td>0.194208</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>-0.294880</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173423</td>\n",
       "      <td>-0.215169</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>-0.015311</td>\n",
       "      <td>0.093588</td>\n",
       "      <td>0.087826</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.022565</td>\n",
       "      <td>0.129272</td>\n",
       "      <td>0.114574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>look</td>\n",
       "      <td>0.054581</td>\n",
       "      <td>0.127487</td>\n",
       "      <td>-0.151036</td>\n",
       "      <td>-0.005508</td>\n",
       "      <td>-0.224009</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.232555</td>\n",
       "      <td>0.107369</td>\n",
       "      <td>-0.185322</td>\n",
       "      <td>0.058561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>-0.080692</td>\n",
       "      <td>-0.142835</td>\n",
       "      <td>-0.223450</td>\n",
       "      <td>0.080660</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>-0.003870</td>\n",
       "      <td>-0.024116</td>\n",
       "      <td>0.164091</td>\n",
       "      <td>0.119459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>size</td>\n",
       "      <td>-0.171825</td>\n",
       "      <td>0.145939</td>\n",
       "      <td>0.017583</td>\n",
       "      <td>-0.107087</td>\n",
       "      <td>-0.072186</td>\n",
       "      <td>0.047046</td>\n",
       "      <td>0.159873</td>\n",
       "      <td>0.072758</td>\n",
       "      <td>-0.126915</td>\n",
       "      <td>0.218353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039657</td>\n",
       "      <td>-0.208206</td>\n",
       "      <td>0.090171</td>\n",
       "      <td>-0.083781</td>\n",
       "      <td>-0.040590</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>-0.050155</td>\n",
       "      <td>0.096652</td>\n",
       "      <td>0.107311</td>\n",
       "      <td>-0.026295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy</td>\n",
       "      <td>0.017106</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>-0.108680</td>\n",
       "      <td>-0.119686</td>\n",
       "      <td>-0.091354</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.053638</td>\n",
       "      <td>-0.008622</td>\n",
       "      <td>0.146764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>-0.186191</td>\n",
       "      <td>0.034582</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>-0.022339</td>\n",
       "      <td>0.028884</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>0.218723</td>\n",
       "      <td>-0.013491</td>\n",
       "      <td>-0.028987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>love</td>\n",
       "      <td>-0.029746</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>-0.098678</td>\n",
       "      <td>-0.013952</td>\n",
       "      <td>-0.094595</td>\n",
       "      <td>-0.001046</td>\n",
       "      <td>0.122878</td>\n",
       "      <td>0.181623</td>\n",
       "      <td>-0.143687</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014108</td>\n",
       "      <td>-0.196971</td>\n",
       "      <td>0.115569</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>-0.024572</td>\n",
       "      <td>0.113253</td>\n",
       "      <td>0.119157</td>\n",
       "      <td>0.122024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shoe</td>\n",
       "      <td>-0.065355</td>\n",
       "      <td>-0.092645</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>0.050878</td>\n",
       "      <td>-0.105065</td>\n",
       "      <td>0.041459</td>\n",
       "      <td>0.208941</td>\n",
       "      <td>-0.052090</td>\n",
       "      <td>0.080999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146384</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.102610</td>\n",
       "      <td>-0.260357</td>\n",
       "      <td>-0.174027</td>\n",
       "      <td>-0.047577</td>\n",
       "      <td>-0.020911</td>\n",
       "      <td>0.050849</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.089279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>great</td>\n",
       "      <td>-0.059158</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>-0.072404</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>-0.104383</td>\n",
       "      <td>-0.037912</td>\n",
       "      <td>0.202679</td>\n",
       "      <td>0.169779</td>\n",
       "      <td>-0.056441</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049963</td>\n",
       "      <td>-0.156396</td>\n",
       "      <td>0.039680</td>\n",
       "      <td>0.034908</td>\n",
       "      <td>-0.031424</td>\n",
       "      <td>0.142564</td>\n",
       "      <td>0.093667</td>\n",
       "      <td>0.096967</td>\n",
       "      <td>0.097154</td>\n",
       "      <td>0.055695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>good</td>\n",
       "      <td>-0.025102</td>\n",
       "      <td>-0.023504</td>\n",
       "      <td>-0.028997</td>\n",
       "      <td>0.055441</td>\n",
       "      <td>-0.068293</td>\n",
       "      <td>-0.075875</td>\n",
       "      <td>0.131287</td>\n",
       "      <td>0.216186</td>\n",
       "      <td>-0.068053</td>\n",
       "      <td>0.064040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>-0.111604</td>\n",
       "      <td>0.057286</td>\n",
       "      <td>-0.058873</td>\n",
       "      <td>-0.109726</td>\n",
       "      <td>0.155792</td>\n",
       "      <td>0.079384</td>\n",
       "      <td>-0.021683</td>\n",
       "      <td>0.051159</td>\n",
       "      <td>0.107291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "wear  -0.006471  0.108129  0.002452  0.009625 -0.138854  0.103454 -0.015824   \n",
       "fit   -0.161161  0.110439 -0.038229 -0.026666 -0.144252  0.009140  0.190725   \n",
       "like   0.072590  0.069709  0.022328 -0.031151 -0.212090  0.035488  0.194208   \n",
       "look   0.054581  0.127487 -0.151036 -0.005508 -0.224009  0.008208  0.232555   \n",
       "size  -0.171825  0.145939  0.017583 -0.107087 -0.072186  0.047046  0.159873   \n",
       "buy    0.017106  0.062912  0.025466 -0.108680 -0.119686 -0.091354  0.079260   \n",
       "love  -0.029746  0.161133 -0.098678 -0.013952 -0.094595 -0.001046  0.122878   \n",
       "shoe  -0.065355 -0.092645  0.039467  0.040138  0.050878 -0.105065  0.041459   \n",
       "great -0.059158  0.003720 -0.072404  0.032074 -0.104383 -0.037912  0.202679   \n",
       "good  -0.025102 -0.023504 -0.028997  0.055441 -0.068293 -0.075875  0.131287   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "wear   0.060735 -0.190063  0.004971  ...  0.098226 -0.191005 -0.126301   \n",
       "fit    0.098752 -0.120438  0.081916  ...  0.009477 -0.108018 -0.030865   \n",
       "like   0.035152 -0.294880 -0.006348  ...  0.173423 -0.215169  0.010825   \n",
       "look   0.107369 -0.185322  0.058561  ...  0.118041 -0.080692 -0.142835   \n",
       "size   0.072758 -0.126915  0.218353  ... -0.039657 -0.208206  0.090171   \n",
       "buy    0.053638 -0.008622  0.146764  ...  0.007689 -0.186191  0.034582   \n",
       "love   0.181623 -0.143687  0.017049  ... -0.014108 -0.196971  0.115569   \n",
       "shoe   0.208941 -0.052090  0.080999  ...  0.146384 -0.004874 -0.102610   \n",
       "great  0.169779 -0.056441  0.056738  ...  0.049963 -0.156396  0.039680   \n",
       "good   0.216186 -0.068053  0.064040  ...  0.080431 -0.111604  0.057286   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "wear   0.075581 -0.174255  0.028864  0.026689  0.048451 -0.018639  0.011287  \n",
       "fit   -0.109473  0.011255  0.074062  0.019416  0.073419  0.069346 -0.013740  \n",
       "like  -0.015311  0.093588  0.087826  0.056260  0.022565  0.129272  0.114574  \n",
       "look  -0.223450  0.080660  0.014717 -0.003870 -0.024116  0.164091  0.119459  \n",
       "size  -0.083781 -0.040590  0.028536 -0.050155  0.096652  0.107311 -0.026295  \n",
       "buy    0.033752 -0.022339  0.028884 -0.015724  0.218723 -0.013491 -0.028987  \n",
       "love   0.124271  0.028174  0.140796 -0.024572  0.113253  0.119157  0.122024  \n",
       "shoe  -0.260357 -0.174027 -0.047577 -0.020911  0.050849  0.027025  0.089279  \n",
       "great  0.034908 -0.031424  0.142564  0.093667  0.096967  0.097154  0.055695  \n",
       "good  -0.058873 -0.109726  0.155792  0.079384 -0.021683  0.051159  0.107291  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take word vectors of most frequent words.\n",
    "num_words = 2000\n",
    "word_embeddings = pd.DataFrame(model.wv.syn0norm[:num_words, :], index=model.wv.index2word[:num_words])\n",
    "word_embeddings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Tiro', 0.5771196484565735),\n",
       " ('climalite', 0.5665316581726074),\n",
       " ('Nike', 0.5498344898223877),\n",
       " ('Adidas', 0.522400975227356),\n",
       " ('New_Balance', 0.5129073858261108)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['adidas'], topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('sandal', 0.47604888677597046),\n",
       " ('running_shoe', 0.4357413649559021),\n",
       " ('sneaker', 0.43562179803848267),\n",
       " ('New_Balances', 0.42014098167419434),\n",
       " ('latin', 0.41360458731651306)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['shoe'], negative=['ugly'], topn=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request key word insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please insert the key word of the product shoe\n"
     ]
    }
   ],
   "source": [
    "search_item=input(\"Please insert the key word of the product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply most_similar method to output the most similar words corresponding to the key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaminzhu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "search_word=model.most_similar(positive=[search_item],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sneaker', 0.8276972770690918),\n",
       " ('sandal', 0.8152226805686951),\n",
       " ('tennis_shoe', 0.7273920178413391),\n",
       " ('running_shoe', 0.7178020477294922),\n",
       " ('boot', 0.6784968972206116)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in search_word:\n",
    "    target_list.append(x[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the list contains top rates of related words through user given key word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sneaker', 'sandal', 'tennis_shoe', 'running_shoe', 'boot']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation and final target list of most related word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sneaker', 'sandal', 'tennis shoe', 'running shoe', 'boot']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list2=[]\n",
    "#remove punctuation\n",
    "for x in target_list:\n",
    "    x=x.replace(\"_\",\" \")\n",
    "    target_list2.append(x)\n",
    "target_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the cleaned review contains the certain word within the target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = reviewnew_df[reviewnew_df['review_clean'].str.contains(target_list2[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>164614</td>\n",
       "      <td>These shoes offer a LOT less support and cushi...</td>\n",
       "      <td>0</td>\n",
       "      <td>shoe offer lot less support cushion i've adjus...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111980</td>\n",
       "      <td>I suffer from flat feet and my Rheumatologist ...</td>\n",
       "      <td>0</td>\n",
       "      <td>suffer flat foot rheumatologist recommend wear...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129853</td>\n",
       "      <td>This was my first purchase of Salomons and I n...</td>\n",
       "      <td>0</td>\n",
       "      <td>first purchase salomon different pair salomon ...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173176</td>\n",
       "      <td>Asics shoes fit me the best of all the running...</td>\n",
       "      <td>0</td>\n",
       "      <td>asics shoe fit best running shoe use never try...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261071</td>\n",
       "      <td>I'm in so love with these New Balance running ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm love new balance running shoe incredibly l...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173241</td>\n",
       "      <td>I have always been a big fan of asics. they al...</td>\n",
       "      <td>0</td>\n",
       "      <td>always big fan asics always fit right never pr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179330</td>\n",
       "      <td>I own Salomon hiking and winter boots and love...</td>\n",
       "      <td>0</td>\n",
       "      <td>salomon hike winter boot love well xt wing als...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187402</td>\n",
       "      <td>I purchased these for my running shoes as I al...</td>\n",
       "      <td>0</td>\n",
       "      <td>purchase running shoe always seem take time li...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92905</td>\n",
       "      <td>I had been searching for some low-profile snea...</td>\n",
       "      <td>0</td>\n",
       "      <td>search low-profile sneaker quite time since pu...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37407</td>\n",
       "      <td>I bought these Crocs for working in a restaura...</td>\n",
       "      <td>0</td>\n",
       "      <td>buy crocs work restaurant kitchen they're comf...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  is_bad_review  \\\n",
       "164614  These shoes offer a LOT less support and cushi...              0   \n",
       "111980  I suffer from flat feet and my Rheumatologist ...              0   \n",
       "129853  This was my first purchase of Salomons and I n...              0   \n",
       "173176  Asics shoes fit me the best of all the running...              0   \n",
       "261071  I'm in so love with these New Balance running ...              0   \n",
       "173241  I have always been a big fan of asics. they al...              0   \n",
       "179330  I own Salomon hiking and winter boots and love...              0   \n",
       "187402  I purchased these for my running shoes as I al...              0   \n",
       "92905   I had been searching for some low-profile snea...              0   \n",
       "37407   I bought these Crocs for working in a restaura...              0   \n",
       "\n",
       "                                             review_clean    neg    neu    pos  \n",
       "164614  shoe offer lot less support cushion i've adjus...  0.000  0.599  0.401  \n",
       "111980  suffer flat foot rheumatologist recommend wear...  0.071  0.625  0.304  \n",
       "129853  first purchase salomon different pair salomon ...  0.027  0.689  0.284  \n",
       "173176  asics shoe fit best running shoe use never try...  0.000  0.720  0.280  \n",
       "261071  i'm love new balance running shoe incredibly l...  0.000  0.731  0.269  \n",
       "173241  always big fan asics always fit right never pr...  0.000  0.739  0.261  \n",
       "179330  salomon hike winter boot love well xt wing als...  0.015  0.732  0.253  \n",
       "187402  purchase running shoe always seem take time li...  0.034  0.719  0.247  \n",
       "92905   search low-profile sneaker quite time since pu...  0.034  0.726  0.240  \n",
       "37407   buy crocs work restaurant kitchen they're comf...  0.000  0.787  0.213  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.nlargest(10, 'pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all review has the word in target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>230472</td>\n",
       "      <td>These boots are not water proof and when I wor...</td>\n",
       "      <td>1</td>\n",
       "      <td>boot water proof wear snow foot soak worm either</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98496</td>\n",
       "      <td>I don't think my calves are wide, but accordin...</td>\n",
       "      <td>0</td>\n",
       "      <td>think calf wide accord boot maker might little...</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45795</td>\n",
       "      <td>Item exactly as shown in the picture.I purchas...</td>\n",
       "      <td>0</td>\n",
       "      <td>item exactly show picture.i purchase caterpill...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138505</td>\n",
       "      <td>I could not get this boot on my kids foot. The...</td>\n",
       "      <td>1</td>\n",
       "      <td>could get boot kid foot actual foot part enoug...</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184797</td>\n",
       "      <td>I have hiked many uphill miles in these and so...</td>\n",
       "      <td>0</td>\n",
       "      <td>hike many uphill mile far show sign wear compa...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173878</td>\n",
       "      <td>I ordered this boots for my daughter. They fit...</td>\n",
       "      <td>0</td>\n",
       "      <td>order boot daughter fit perfectly warm nice lo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184295</td>\n",
       "      <td>Nice boots, is a good Leather, very nice casua...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice boot good leather nice casual style fit p...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184295</td>\n",
       "      <td>Nice boots, is a good Leather, very nice casua...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice boot good leather nice casual style fit p...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43010</td>\n",
       "      <td>Great fit, comfy for hunting boots!</td>\n",
       "      <td>0</td>\n",
       "      <td>great fit comfy hunt boot</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43010</td>\n",
       "      <td>Great fit, comfy for hunting boots!</td>\n",
       "      <td>0</td>\n",
       "      <td>great fit comfy hunt boot</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  is_bad_review  \\\n",
       "230472  These boots are not water proof and when I wor...              1   \n",
       "98496   I don't think my calves are wide, but accordin...              0   \n",
       "45795   Item exactly as shown in the picture.I purchas...              0   \n",
       "138505  I could not get this boot on my kids foot. The...              1   \n",
       "184797  I have hiked many uphill miles in these and so...              0   \n",
       "...                                                   ...            ...   \n",
       "173878  I ordered this boots for my daughter. They fit...              0   \n",
       "184295  Nice boots, is a good Leather, very nice casua...              0   \n",
       "184295  Nice boots, is a good Leather, very nice casua...              0   \n",
       "43010                 Great fit, comfy for hunting boots!              0   \n",
       "43010                 Great fit, comfy for hunting boots!              0   \n",
       "\n",
       "                                             review_clean    neg    neu    pos  \n",
       "230472   boot water proof wear snow foot soak worm either  0.000  1.000  0.000  \n",
       "98496   think calf wide accord boot maker might little...  0.115  0.885  0.000  \n",
       "45795   item exactly show picture.i purchase caterpill...  0.000  1.000  0.000  \n",
       "138505  could get boot kid foot actual foot part enoug...  0.143  0.857  0.000  \n",
       "184797  hike many uphill mile far show sign wear compa...  0.052  0.948  0.000  \n",
       "...                                                   ...    ...    ...    ...  \n",
       "173878  order boot daughter fit perfectly warm nice lo...  0.000  0.398  0.602  \n",
       "184295  nice boot good leather nice casual style fit p...  0.000  0.383  0.617  \n",
       "184295  nice boot good leather nice casual style fit p...  0.000  0.383  0.617  \n",
       "43010                           great fit comfy hunt boot  0.000  0.367  0.633  \n",
       "43010                           great fit comfy hunt boot  0.000  0.367  0.633  \n",
       "\n",
       "[2560 rows x 6 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the dataframe contains all the related words that are in the target list\n",
    "for x in target_list2:\n",
    "    target_df = reviewnew_df[reviewnew_df['review_clean'].str.contains(x)]\n",
    "    target_df=target_df.append(target_df)\n",
    "target_df.sort_values(\"pos\", inplace = True) \n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=target_df.nlargest(10, 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>43010</td>\n",
       "      <td>Great fit, comfy for hunting boots!</td>\n",
       "      <td>0</td>\n",
       "      <td>great fit comfy hunt boot</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43010</td>\n",
       "      <td>Great fit, comfy for hunting boots!</td>\n",
       "      <td>0</td>\n",
       "      <td>great fit comfy hunt boot</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184295</td>\n",
       "      <td>Nice boots, is a good Leather, very nice casua...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice boot good leather nice casual style fit p...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184295</td>\n",
       "      <td>Nice boots, is a good Leather, very nice casua...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice boot good leather nice casual style fit p...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173878</td>\n",
       "      <td>I ordered this boots for my daughter. They fit...</td>\n",
       "      <td>0</td>\n",
       "      <td>order boot daughter fit perfectly warm nice lo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173878</td>\n",
       "      <td>I ordered this boots for my daughter. They fit...</td>\n",
       "      <td>0</td>\n",
       "      <td>order boot daughter fit perfectly warm nice lo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248662</td>\n",
       "      <td>These boots have a clean, smooth look, no extr...</td>\n",
       "      <td>0</td>\n",
       "      <td>boot clean smooth look extra buckle etc nice f...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248662</td>\n",
       "      <td>These boots have a clean, smooth look, no extr...</td>\n",
       "      <td>0</td>\n",
       "      <td>boot clean smooth look extra buckle etc nice f...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247822</td>\n",
       "      <td>As always it is a beautiful rich green color, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>always beautiful rich green color fit perfectl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247822</td>\n",
       "      <td>As always it is a beautiful rich green color, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>always beautiful rich green color fit perfectl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  is_bad_review  \\\n",
       "43010                 Great fit, comfy for hunting boots!              0   \n",
       "43010                 Great fit, comfy for hunting boots!              0   \n",
       "184295  Nice boots, is a good Leather, very nice casua...              0   \n",
       "184295  Nice boots, is a good Leather, very nice casua...              0   \n",
       "173878  I ordered this boots for my daughter. They fit...              0   \n",
       "173878  I ordered this boots for my daughter. They fit...              0   \n",
       "248662  These boots have a clean, smooth look, no extr...              0   \n",
       "248662  These boots have a clean, smooth look, no extr...              0   \n",
       "247822  As always it is a beautiful rich green color, ...              0   \n",
       "247822  As always it is a beautiful rich green color, ...              0   \n",
       "\n",
       "                                             review_clean    neg    neu    pos  \n",
       "43010                           great fit comfy hunt boot  0.000  0.367  0.633  \n",
       "43010                           great fit comfy hunt boot  0.000  0.367  0.633  \n",
       "184295  nice boot good leather nice casual style fit p...  0.000  0.383  0.617  \n",
       "184295  nice boot good leather nice casual style fit p...  0.000  0.383  0.617  \n",
       "173878  order boot daughter fit perfectly warm nice lo...  0.000  0.398  0.602  \n",
       "173878  order boot daughter fit perfectly warm nice lo...  0.000  0.398  0.602  \n",
       "248662  boot clean smooth look extra buckle etc nice f...  0.067  0.364  0.570  \n",
       "248662  boot clean smooth look extra buckle etc nice f...  0.067  0.364  0.570  \n",
       "247822  always beautiful rich green color fit perfectl...  0.000  0.436  0.564  \n",
       "247822  always beautiful rich green color fit perfectl...  0.000  0.436  0.564  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop_duplicates(subset='reviewText', keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the results leave the highest pos score from sentimental analysist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_bad_review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>43010</td>\n",
       "      <td>Great fit, comfy for hunting boots!</td>\n",
       "      <td>0</td>\n",
       "      <td>great fit comfy hunt boot</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184295</td>\n",
       "      <td>Nice boots, is a good Leather, very nice casua...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice boot good leather nice casual style fit p...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173878</td>\n",
       "      <td>I ordered this boots for my daughter. They fit...</td>\n",
       "      <td>0</td>\n",
       "      <td>order boot daughter fit perfectly warm nice lo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248662</td>\n",
       "      <td>These boots have a clean, smooth look, no extr...</td>\n",
       "      <td>0</td>\n",
       "      <td>boot clean smooth look extra buckle etc nice f...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247822</td>\n",
       "      <td>As always it is a beautiful rich green color, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>always beautiful rich green color fit perfectl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  is_bad_review  \\\n",
       "43010                 Great fit, comfy for hunting boots!              0   \n",
       "184295  Nice boots, is a good Leather, very nice casua...              0   \n",
       "173878  I ordered this boots for my daughter. They fit...              0   \n",
       "248662  These boots have a clean, smooth look, no extr...              0   \n",
       "247822  As always it is a beautiful rich green color, ...              0   \n",
       "\n",
       "                                             review_clean    neg    neu    pos  \n",
       "43010                           great fit comfy hunt boot  0.000  0.367  0.633  \n",
       "184295  nice boot good leather nice casual style fit p...  0.000  0.383  0.617  \n",
       "173878  order boot daughter fit perfectly warm nice lo...  0.000  0.398  0.602  \n",
       "248662  boot clean smooth look extra buckle etc nice f...  0.067  0.364  0.570  \n",
       "247822  always beautiful rich green color fit perfectl...  0.000  0.436  0.564  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search back into original dataframe, maybe not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>is_bad_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>247822</td>\n",
       "      <td>A3R72ZJRSS90VX</td>\n",
       "      <td>B00BBPVIKO</td>\n",
       "      <td>fairenough</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>As always it is a beautiful rich green color, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfectly Patty</td>\n",
       "      <td>1388016000</td>\n",
       "      <td>12 26, 2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43010</td>\n",
       "      <td>A3N3K9BN1KT86H</td>\n",
       "      <td>B000TH4ST8</td>\n",
       "      <td>Lindsey Comings</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great fit, comfy for hunting boots!</td>\n",
       "      <td>5</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1404950400</td>\n",
       "      <td>07 10, 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184295</td>\n",
       "      <td>A3AWOYYDRI3H6R</td>\n",
       "      <td>B0076OWNZS</td>\n",
       "      <td>Sky</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice boots, is a good Leather, very nice casua...</td>\n",
       "      <td>5</td>\n",
       "      <td>Lovely!</td>\n",
       "      <td>1382140800</td>\n",
       "      <td>10 19, 2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173878</td>\n",
       "      <td>A2BHJWY7BJQKU2</td>\n",
       "      <td>B006JCVKDY</td>\n",
       "      <td>Ili</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I ordered this boots for my daughter. They fit...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good show boots</td>\n",
       "      <td>1384992000</td>\n",
       "      <td>11 21, 2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248662</td>\n",
       "      <td>A5WR7RZUJUIGA</td>\n",
       "      <td>B00BFZQIE6</td>\n",
       "      <td>Just A Gal</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>These boots have a clean, smooth look, no extr...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice boots, nice price</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>01 1, 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247822</td>\n",
       "      <td>A3R72ZJRSS90VX</td>\n",
       "      <td>B00BBPVIKO</td>\n",
       "      <td>fairenough</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>As always it is a beautiful rich green color, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfectly Patty</td>\n",
       "      <td>1388016000</td>\n",
       "      <td>12 26, 2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin     reviewerName helpful  \\\n",
       "247822  A3R72ZJRSS90VX  B00BBPVIKO       fairenough  [0, 0]   \n",
       "43010   A3N3K9BN1KT86H  B000TH4ST8  Lindsey Comings  [0, 0]   \n",
       "184295  A3AWOYYDRI3H6R  B0076OWNZS              Sky  [0, 0]   \n",
       "173878  A2BHJWY7BJQKU2  B006JCVKDY              Ili  [0, 1]   \n",
       "248662   A5WR7RZUJUIGA  B00BFZQIE6       Just A Gal  [0, 1]   \n",
       "247822  A3R72ZJRSS90VX  B00BBPVIKO       fairenough  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "247822  As always it is a beautiful rich green color, ...        5   \n",
       "43010                 Great fit, comfy for hunting boots!        5   \n",
       "184295  Nice boots, is a good Leather, very nice casua...        5   \n",
       "173878  I ordered this boots for my daughter. They fit...        5   \n",
       "248662  These boots have a clean, smooth look, no extr...        5   \n",
       "247822  As always it is a beautiful rich green color, ...        5   \n",
       "\n",
       "                       summary  unixReviewTime   reviewTime  is_bad_review  \n",
       "247822         Perfectly Patty      1388016000  12 26, 2013              0  \n",
       "43010               Five Stars      1404950400  07 10, 2014              0  \n",
       "184295                 Lovely!      1382140800  10 19, 2013              0  \n",
       "173878         Good show boots      1384992000  11 21, 2013              0  \n",
       "248662  Nice boots, nice price      1388534400   01 1, 2014              0  \n",
       "247822         Perfectly Patty      1388016000  12 26, 2013              0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in final_df['reviewText']:\n",
    "    data_original=data_original.append(data.loc[data['reviewText'] == x])\n",
    "data_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the suggested products ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247822    B00BBPVIKO\n",
       "43010     B000TH4ST8\n",
       "184295    B0076OWNZS\n",
       "173878    B006JCVKDY\n",
       "248662    B00BFZQIE6\n",
       "247822    B00BBPVIKO\n",
       "Name: asin, dtype: object"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original['asin']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
